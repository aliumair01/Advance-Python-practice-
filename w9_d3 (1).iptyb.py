# -*- coding: utf-8 -*-
"""W9_D3.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1KmYzZDtq6I1C7IX6TmpiFCebTj4AJmkV
"""

import seaborn as sns
import numpy as np
import random
import os
import cv2
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.svm import SVC
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
import matplotlib.pyplot as plt

!wget https://data.vision.ee.ethz.ch/cvl/food-101.tar.gz
!tar -xvf food-101.tar.gz

def preprocess_images(image_dir, size=(64, 64)):
    images = []
    labels = []
    breed_labels = os.listdir(image_dir) # breed names list
    for breed in breed_labels:
        breed_path = os.path.join(image_dir, breed)
        if os.path.isdir(breed_path):
            for img_name in os.listdir(breed_path):
                img_path = os.path.join(breed_path, img_name)
                img = cv2.imread(img_path)
                img = cv2.resize(img, size)
                img = img.flatten()
                images.append(img)
                labels.append(breed)
    return np.array(images), np.array(labels)

# Loading and preprocessing
X, y = preprocess_images("/content/food-101/images")

from sklearn.preprocessing import LabelEncoder
le = LabelEncoder()
y_encoded = le.fit_transform(y)

x1=X[5100:6190]
y1= y_encoded[5100:6190]

X_train, X_test, y_train, y_test = train_test_split(x1, y1, test_size=0.2, random_state=42)

random_indices = random.sample(range(len(X_test)), 5)
fig, axes = plt.subplots(1, 5, figsize=(20, 10))

for i, idx in enumerate(random_indices):
    image = X_test[idx].reshape(64, 64, 3)
    label = le.inverse_transform([y_test[idx]])[0]  # Decode label back to its breed name

    axes[i].imshow(image)
    axes[i].set_title(label)
    axes[i].axis('off')

plt.tight_layout()
plt.show()

svm= SVC(kernel='linear')
svm.fit(X_train, y_train)

rf = RandomForestClassifier(n_estimators=100)
rf.fit(X_train, y_train)

# SVM
svm_predictions = svm.predict(X_test)
svm_accuracy = accuracy_score(y_test, svm_predictions)

print(f"SVM Accuracy: {svm_accuracy * 100:.2f}%")
print(classification_report(y_test, svm_predictions))

# Random Forest
rf_predictions = rf.predict(X_test)
rf_accuracy = accuracy_score(y_test, rf_predictions)

print(f"Random Forest Accuracy: {rf_accuracy * 100:.2f}%")
print(classification_report(y_test, rf_predictions))

print(f"Random Forest Accuracy: {rf_accuracy * 100:.2f}%")
print(classification_report(y_test, rf_predictions))

# for SVM
plt.figure(figsize=(10,7))
plt.title('SVM Confusion Matrix')
sns.heatmap(confusion_matrix(y_test, svm_predictions), annot=True, fmt='d', cmap='Blues')

# for Random Forest
plt.figure(figsize=(10,7))
plt.title('Random Forest Confusion Matrix')
sns.heatmap(confusion_matrix(y_test, rf_predictions), annot=True, fmt='d', cmap='Blues')

from sklearn.model_selection import GridSearchCV

svm_params = {'C': [0.1, 1, 10], 'kernel': ['linear', 'rbf']}
svm_grid = GridSearchCV(SVC(), svm_params, cv=3)
svm_grid.fit(X_train, y_train)
print("Best SVM parameters:", svm_grid.best_params_)

rf_params = {'n_estimators': [100, 200, 300], 'max_depth': [None, 10, 20, 30]}
rf_grid = GridSearchCV(RandomForestClassifier(), rf_params, cv=3)
rf_grid.fit(X_train, y_train)
print("Best RF parameters:", rf_grid.best_params_)

import joblib
joblib.dump(rf, 'rf_model.pkl')  # saved
joblib.dump(svm, 'svm_model.pkl')  #

loaded_rf_model = joblib.load('rf_model.pkl')
loaded_svm_model = joblib.load('svm_model.pkl')

